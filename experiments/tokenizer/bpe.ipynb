{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebb19a2",
   "metadata": {},
   "source": [
    "## Basic Byte-Pair-Encoding(BPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a735fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBPE:\n",
    "\n",
    "    def __init__(self, vocab_size: int):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.vocab = {idx: bytes([idx]) for idx in range(256)} # BPE definition\n",
    "        self.merges = dict()\n",
    "\n",
    "    def train(self, text: str):\n",
    "        \"\"\"\n",
    "        1. Encode text into UTF-8 format.\n",
    "        2. Search for pairs and merges.\n",
    "        3. Apply merges and repeat 2. until end condition.\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = text.encode('utf-8')\n",
    "        tokens = list(map(int, tokens))\n",
    "\n",
    "        while len(self.merges) + 256 <= self.vocab_size:\n",
    "            # compute tokens stats\n",
    "            tokens_stats = compute_pair_of_tokens_stats(tokens)\n",
    "            # get most common pair of tokens\n",
    "            most_common_pair = max(tokens_stats, key=tokens_stats.get)\n",
    "            new_token_id = len(self.merges) + 1 + 256 # UTF-8 has 256 ints\n",
    "            # save change\n",
    "            self.merges[most_common_pair] = new_token_id\n",
    "            # apply change\n",
    "            tokens = merge_pair(tokens, pair=most_common_pair, idx=new_token_id)\n",
    "\n",
    "        # update tokens map\n",
    "        for (p0, p1), idx in self.merges.items():\n",
    "            self.vocab[idx] = self.vocab[p0] + self.vocab[p1]\n",
    "    \n",
    "    def encode(self, text: str):\n",
    "        \"\"\"\n",
    "        1. Compute UTF-8 encoding of text.\n",
    "        2. Apply merges to convert UTF-8 encoding to BPE encoding.\n",
    "        \"\"\"\n",
    "        tokens = list(text.encode('utf-8'))\n",
    "        while len(tokens) >= 2:\n",
    "            stats = compute_pair_of_tokens_stats(tokens)\n",
    "            pair = min(stats, key=lambda p: self.merges.get(p, float(\"inf\")))\n",
    "            if pair not in self.merges:\n",
    "                break # nothing else can be merged\n",
    "            idx = self.merges[pair]\n",
    "            tokens = merge_pair(tokens, pair, idx)\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        \"\"\"\n",
    "        1. Convert tokens from BPE enconding to UTF-8 encoding.\n",
    "        2. Decode UTF-8 to text.\n",
    "        \"\"\"\n",
    "        text = b\"\".join(self.vocab[x] for x in tokens)\n",
    "        text = text.decode(\"utf-8\", errors=\"replace\")\n",
    "        return text\n",
    "\n",
    "\n",
    "def compute_pair_of_tokens_stats(tokens):\n",
    "\n",
    "    info = {}\n",
    "    for pair in zip(tokens, tokens[1:]):\n",
    "        if pair not in info.keys():\n",
    "            info[pair] = 1\n",
    "        else:\n",
    "            info[pair] += 1\n",
    "    return info\n",
    "\n",
    "def merge_pair(tokens, pair, idx):\n",
    "    new_list = []\n",
    "    i = 0\n",
    "    total_tokens = len(tokens)\n",
    "    while i < total_tokens:\n",
    "        if i < total_tokens - 1 and tokens[i] == pair[0] and tokens[i+1] == pair[1]:\n",
    "            new_list.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            new_list.append(tokens[i])\n",
    "            i += 1\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5539ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-01-14 16:31:24--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolviendo raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Conectando con raw.githubusercontent.com (raw.githubusercontent.com)[185.199.110.133]:443... conectado.\n",
      "Petición HTTP enviada, esperando respuesta... 200 OK\n",
      "Longitud: 1115394 (1,1M) [text/plain]\n",
      "Guardando como: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1,06M  --.-KB/s    en 0,09s   \n",
      "\n",
      "2026-01-14 16:31:24 (12,3 MB/s) - ‘input.txt’ guardado [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We always start with a dataset to train on. Let's download the tiny shakespeare dataset\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c5a68fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded example:  o s \n",
      "Encoded example:  [70, 300, 297]\n"
     ]
    }
   ],
   "source": [
    "text = open(\"input.txt\", \"r\").read()\n",
    "\n",
    "bpe = BasicBPE(vocab_size=300)\n",
    "bpe.train(text)\n",
    "\n",
    "decoding_example = bpe.decode([270,260])\n",
    "print(\"Decoded example: \", decoding_example)\n",
    "\n",
    "encoding_example = bpe.encode(text[:5])\n",
    "print(\"Encoded example: \", encoding_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68dcb934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(bpe.decode(bpe.encode(\"hello world\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "606b4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens using UFT-8: 1115394\n",
      "Number of tokens using BPE: 785969\n",
      "Compression ratio: 141.91323067449224\n"
     ]
    }
   ],
   "source": [
    "tokens_level_utf8 = text.encode(\"utf-8\")\n",
    "tokens_level_bpe = bpe.encode(text)\n",
    "print(f\"Number of tokens using UFT-8: {len(tokens_level_utf8)}\")\n",
    "print(f\"Number of tokens using BPE: {len(tokens_level_bpe)}\")\n",
    "print(f\"Compression ratio: {len(tokens_level_utf8)/len(tokens_level_bpe)*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
